{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd5606c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\santh\\anaconda3\\lib\\site-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\santh\\anaconda3\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\santh\\anaconda3\\lib\\site-packages (from kaggle) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\santh\\anaconda3\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\users\\santh\\anaconda3\\lib\\site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\santh\\anaconda3\\lib\\site-packages (from kaggle) (4.65.0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\santh\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\santh\\anaconda3\\lib\\site-packages (from kaggle) (2.0.7)\n",
      "Requirement already satisfied: bleach in c:\\users\\santh\\anaconda3\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\santh\\anaconda3\\lib\\site-packages (from bleach->kaggle) (23.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\santh\\anaconda3\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\santh\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\santh\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\santh\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\santh\\anaconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# installing kaggle library\n",
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fc6441",
   "metadata": {},
   "source": [
    "Upload Kaggle.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cdeab0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\santh/.kaggle\\\\kaggle.json'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configuring the path of kaggle.json file\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Create the .kaggle directory if it doesn't exist\n",
    "kaggle_dir = os.path.expanduser('~/.kaggle')\n",
    "if not os.path.exists(kaggle_dir):\n",
    "    os.makedirs(kaggle_dir)\n",
    "\n",
    "# Move the kaggle.json file to the .kaggle directory\n",
    "shutil.move('kaggle.json', os.path.join(kaggle_dir, 'kaggle.json'))\n",
    "\n",
    "# Set permission for the file (Windows doesn't use chmod, so this can be skipped)\n",
    "# This is generally for Unix-based systems, so in Windows you can ignore it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b86728c",
   "metadata": {},
   "source": [
    "Verify Kaggle Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e5d2bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                                          title                                               size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
      "-----------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
      "valakhorasani/mobile-device-usage-and-user-behavior-dataset  Mobile Device Usage and User Behavior Dataset       11KB  2024-09-28 20:21:12           7306        132  1.0              \n",
      "lainguyn123/student-performance-factors                      Student Performance Factors                         94KB  2024-09-02 10:53:57          35676        630  1.0              \n",
      "valakhorasani/gym-members-exercise-dataset                   Gym Members Exercise Dataset                        22KB  2024-10-06 11:27:38           3680         76  1.0              \n",
      "mohamedyosef101/2024-olympics-medals-and-economic-status     2024 Olympics Medals and Economic status             2KB  2024-10-13 12:39:58           1534         23  1.0              \n",
      "mayurkadam9833/top-100-imdb-movies                           Top 100 IMDB movies                                  9KB  2024-09-30 14:06:41           1195         22  1.0              \n",
      "octopusteam/imdb-top-1000-movies                             IMDb Top 1000 Movies                                24KB  2024-10-18 08:00:05            873         23  1.0              \n",
      "abdulszz/spotify-most-streamed-songs                         Spotify Most Streamed Songs                         60KB  2024-09-07 18:23:14          14298        181  1.0              \n",
      "arpitsinghaiml/u-s-crime-dataset                             U.S. Crime Dataset (Jan. 2020 - Sept. 2024)         48MB  2024-10-11 05:11:00            744         21  0.9411765        \n",
      "assemelqirsh/covid19-dataset                                 Covid19_Dataset                                     10MB  2024-10-01 11:30:44           1409         21  1.0              \n",
      "ankulsharma150/marketing-analytics-project                   Marketing Analytics Project                         38KB  2024-10-01 09:27:22           1752         30  1.0              \n",
      "prajwaldongre/top-100-healthiest-food-in-the-world           100 Healthiest Foods:Nutrition and Origin dataset    3KB  2024-10-11 09:40:41           1436         35  1.0              \n",
      "mafzal19/electric-vehicle-sales-by-state-in-india            Electric Vehicle Sales by State in India           453KB  2024-10-11 18:59:45           1541         28  1.0              \n",
      "b'waqi786/remote-work-and-mental-health                        Remote Work & Mental Health \\xf0\\x9f\\x8c\\x8d\\xf0\\x9f\\xa7\\xa0                      93KB  2024-09-22 11:44:29           6551         91  1.0              '\n",
      "ankulsharma150/netflix-data-analysis                         Netflix Data Analysis                                1MB  2024-10-15 08:02:26           1177         21  1.0              \n",
      "b'waqi786/youth-smoking-and-drug-dataset                       Youth Smoking and Drug Dataset \\xf0\\x9f\\x9a\\xad\\xf0\\x9f\\x92\\x8a                  152KB  2024-10-08 15:22:23           2041         37  1.0              '\n",
      "ka66ledata/gym-membership-dataset                            Gym Membership Dataset                              24KB  2024-10-14 06:48:29           1644         27  1.0              \n",
      "valakhorasani/best-books-of-the-decade-2020s                 Best Books of the Decade: 2020's                     3MB  2024-10-18 07:24:43            601         29  1.0              \n",
      "alexandrakim2201/spotify-dataset                             Spotify User Reviews                                 3MB  2024-10-03 10:36:36           1311         31  1.0              \n",
      "shreyadutta1116/parkinsons-disease                           Parkinson's Disease                                225KB  2024-10-15 18:17:37            609         23  0.88235295       \n",
      "alexandervarlamov/cars-trucks-bikes-buses-in-movies          Cars, Trucks, Bikes, Buses in Movies (1900-2024)    64MB  2024-10-12 15:58:10            653         28  0.9411765        \n"
     ]
    }
   ],
   "source": [
    "# Test if Kaggle API is working\n",
    "!kaggle datasets list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bb9a25",
   "metadata": {},
   "source": [
    "Importing Twitter Sentiment Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79239421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/kazanova/sentiment140\n",
      "License(s): other\n",
      "sentiment140.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "# API to fetch dataset from kaggle\n",
    "! kaggle datasets download -d kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71580f01",
   "metadata": {},
   "source": [
    "Unzip the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46145554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Unzip the dataset\n",
    "with zipfile.ZipFile('sentiment140.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()  # Extracts to the current directory\n",
    "\n",
    "# Extract to a specific folder\n",
    "with zipfile.ZipFile('sentiment140.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('path/to/directory')  # Replace with your directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be66de",
   "metadata": {},
   "source": [
    "Import the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0d21105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'path',\n",
       " 'sentiment140.zip',\n",
       " 'training.1600000.processed.noemoticon.csv',\n",
       " 'Untitled.ipynb']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin-1')  # Adjust the file name based on the extracted files\n",
    "# List files in the current directory\n",
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4777232b",
   "metadata": {},
   "source": [
    "Understanding the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd55a6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag           user  \\\n",
       "0       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY  scotthamilton   \n",
       "1       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY       mattycus   \n",
       "2       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY        ElleCTF   \n",
       "3       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         Karoli   \n",
       "4       0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY       joy_wolf   \n",
       "\n",
       "                                                text  \n",
       "0  is upset that he can't update his Facebook by ...  \n",
       "1  @Kenichan I dived many times for the ball. Man...  \n",
       "2    my whole body feels itchy and like its on fire   \n",
       "3  @nationwideclass no, it's not behaving at all....  \n",
       "4                      @Kwesidei not the whole crew   "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns=['target','id','date','flag','user','text']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145a6b63",
   "metadata": {},
   "source": [
    "Importing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6689e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cabaec56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\santh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75c2674d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# Printing the stopwords in english\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46036e4",
   "metadata": {},
   "source": [
    "Data Processing\n",
    "\n",
    "loading the data from csv file to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dc307a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag           user  \\\n",
       "0       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY  scotthamilton   \n",
       "1       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY       mattycus   \n",
       "2       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY        ElleCTF   \n",
       "3       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         Karoli   \n",
       "4       0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY       joy_wolf   \n",
       "\n",
       "                                                text  \n",
       "0  is upset that he can't update his Facebook by ...  \n",
       "1  @Kenichan I dived many times for the ball. Man...  \n",
       "2    my whole body feels itchy and like its on fire   \n",
       "3  @nationwideclass no, it's not behaving at all....  \n",
       "4                      @Kwesidei not the whole crew   "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use raw string notation by adding 'r' before the string\n",
    "twitter_data = pd.read_csv(r\"C:\\Users\\santh\\Untitled Folder\\training.1600000.processed.noemoticon.csv\", encoding='ISO-8859-1')\n",
    "# Assign column names\n",
    "twitter_data.columns = ['target', 'id', 'date', 'flag', 'user', 'text']\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "twitter_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6144260e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599999, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkind the number of rows and columns\n",
    "twitter_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66330c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "id        0\n",
       "date      0\n",
       "flag      0\n",
       "user      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting the number of missing values\n",
    "\n",
    "twitter_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "065d901c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "4    800000\n",
       "0    799999\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the distribution of the target column\n",
    "\n",
    "twitter_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290b95f6",
   "metadata": {},
   "source": [
    "Converting the target \"4\" to \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "124370c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data.replace({'target': {4:1}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8dc07ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    800000\n",
       "0    799999\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the distribution of the target column\n",
    "\n",
    "twitter_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13177eb9",
   "metadata": {},
   "source": [
    "0 --> Negative Tweet\n",
    "\n",
    "1 --> Positive Tweet\n",
    "\n",
    "Stemming\n",
    "\n",
    "Stemming is the process of reducing a word to its Root word\n",
    "\n",
    "exmple: actor, actress, acting = act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "013cbd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1aa2191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def steming(content):\n",
    "\n",
    "  stemmed_content = re.sub('[^a-zA-z]',' ',content)\n",
    "  stemmed_content = stemmed_content.lower()\n",
    "  stemmed_content = stemmed_content.split()\n",
    "  stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "  stemmed_content = ' '.join(stemmed_content)\n",
    "\n",
    "\n",
    "  return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "293c89cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data['stemmed_content'] = twitter_data['text'].apply(steming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73d583ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>stemmed_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset updat facebook text might cri result sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>kenichan dive mani time ball manag save rest g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>nationwideclass behav mad see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>kwesidei whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag           user  \\\n",
       "0       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY  scotthamilton   \n",
       "1       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY       mattycus   \n",
       "2       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY        ElleCTF   \n",
       "3       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         Karoli   \n",
       "4       0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY       joy_wolf   \n",
       "\n",
       "                                                text  \\\n",
       "0  is upset that he can't update his Facebook by ...   \n",
       "1  @Kenichan I dived many times for the ball. Man...   \n",
       "2    my whole body feels itchy and like its on fire    \n",
       "3  @nationwideclass no, it's not behaving at all....   \n",
       "4                      @Kwesidei not the whole crew    \n",
       "\n",
       "                                     stemmed_content  \n",
       "0  upset updat facebook text might cri result sch...  \n",
       "1  kenichan dive mani time ball manag save rest g...  \n",
       "2                    whole bodi feel itchi like fire  \n",
       "3                      nationwideclass behav mad see  \n",
       "4                                kwesidei whole crew  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9685e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          upset updat facebook text might cri result sch...\n",
      "1          kenichan dive mani time ball manag save rest g...\n",
      "2                            whole bodi feel itchi like fire\n",
      "3                              nationwideclass behav mad see\n",
      "4                                        kwesidei whole crew\n",
      "                                 ...                        \n",
      "1599994                           woke school best feel ever\n",
      "1599995    thewdb com cool hear old walt interview http b...\n",
      "1599996                         readi mojo makeov ask detail\n",
      "1599997    happi th birthday boo alll time tupac amaru sh...\n",
      "1599998    happi charitytuesday thenspcc sparkschar speak...\n",
      "Name: stemmed_content, Length: 1599999, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(twitter_data['stemmed_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe6ddac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          0\n",
      "1          0\n",
      "2          0\n",
      "3          0\n",
      "4          0\n",
      "          ..\n",
      "1599994    1\n",
      "1599995    1\n",
      "1599996    1\n",
      "1599997    1\n",
      "1599998    1\n",
      "Name: target, Length: 1599999, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(twitter_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cad8a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating the data and label\n",
    "\n",
    "X = twitter_data['stemmed_content'].values\n",
    "Y = twitter_data['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a11a05b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['upset updat facebook text might cri result school today also blah'\n",
      " 'kenichan dive mani time ball manag save rest go bound'\n",
      " 'whole bodi feel itchi like fire' ... 'readi mojo makeov ask detail'\n",
      " 'happi th birthday boo alll time tupac amaru shakur'\n",
      " 'happi charitytuesday thenspcc sparkschar speakinguph h']\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23762e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edd9140",
   "metadata": {},
   "source": [
    "Splitting the data to training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a11647f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599999,) (1279999,) (320000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)\n",
    "\n",
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2dec1942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['watch saw iv drink lil wine'\n",
      " 'hire anoth employe gourmet point current hurri'\n",
      " 'punish know much work tomorrow everyon els get day' ...\n",
      " 'ohjustjak awkward crush nph amazingg'\n",
      " 'oliveandfig wow never tweet nah yet tuesday spoil'\n",
      " 'that_girl_jenn stay twitter b c got back late amp tri relax enough sleep work amp awak']\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e128ee84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['school someon slap acrosss face caus stay class total dragggg poor poor kitti'\n",
      " 'ah may show w ruth kim amp geoffrey sanhueza'\n",
      " 'dad comput turn even though weird mean download song want' ...\n",
      " 'destini nevertheless hooray member wonder safe trip'\n",
      " 'strawberri heavi appar broke blender epic fuck fail' 'supersandro thank']\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5ec45d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the texttual data to numerical data\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44ff88aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 464907)\t0.44755968424484005\n",
      "  (0, 247566)\t0.4211677185669695\n",
      "  (0, 116313)\t0.37428429359397636\n",
      "  (0, 194742)\t0.5293567683337778\n",
      "  (0, 373033)\t0.35766686591229396\n",
      "  (0, 458362)\t0.2721675481983611\n",
      "  (1, 181532)\t0.3783460265618032\n",
      "  (1, 92615)\t0.3300113641102886\n",
      "  (1, 336609)\t0.31277964698237826\n",
      "  (1, 160607)\t0.49260230408176026\n",
      "  (1, 127172)\t0.4307005603768187\n",
      "  (1, 23001)\t0.25281727079702565\n",
      "  (1, 175881)\t0.39754131995016506\n",
      "  (2, 100219)\t0.22341924630468818\n",
      "  (2, 154375)\t0.22130115521624924\n",
      "  (2, 125253)\t0.3986508849353605\n",
      "  (2, 132426)\t0.33174383935487023\n",
      "  (2, 433486)\t0.28960001302922206\n",
      "  (2, 467565)\t0.23562584799521835\n",
      "  (2, 294403)\t0.2849989296353406\n",
      "  (2, 232688)\t0.26260681919651707\n",
      "  (2, 343356)\t0.5852851415328681\n",
      "  (3, 367795)\t0.30871788531388655\n",
      "  (3, 50489)\t0.6886835448480676\n",
      "  (3, 349108)\t0.46555629423386596\n",
      "  :\t:\n",
      "  (1279996, 311691)\t0.47880627020252514\n",
      "  (1279996, 16702)\t0.4366940449213088\n",
      "  (1279996, 32710)\t0.37397170429854387\n",
      "  (1279996, 91074)\t0.3425177168682021\n",
      "  (1279997, 317032)\t0.613141027487443\n",
      "  (1279997, 298955)\t0.34784708899529887\n",
      "  (1279997, 468138)\t0.262612492777912\n",
      "  (1279997, 476780)\t0.2543512264446866\n",
      "  (1279997, 439537)\t0.3222236553149022\n",
      "  (1279997, 304059)\t0.24197863512466855\n",
      "  (1279997, 440677)\t0.2326235308005553\n",
      "  (1279997, 398658)\t0.3910308994808248\n",
      "  (1279998, 421122)\t0.49758503849323543\n",
      "  (1279998, 354798)\t0.29775579984446054\n",
      "  (1279998, 32313)\t0.2893729521176361\n",
      "  (1279998, 34825)\t0.18377279084244985\n",
      "  (1279998, 437358)\t0.21310107774291198\n",
      "  (1279998, 442238)\t0.20290268138344408\n",
      "  (1279998, 401776)\t0.25747925781534087\n",
      "  (1279998, 17977)\t0.38910032406861256\n",
      "  (1279998, 128102)\t0.2726466315936536\n",
      "  (1279998, 240510)\t0.25265740655891555\n",
      "  (1279998, 160370)\t0.18046383588405498\n",
      "  (1279998, 390652)\t0.20845071565923867\n",
      "  (1279998, 467565)\t0.16665660347815192\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7883dfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 435028)\t0.26230925717781944\n",
      "  (0, 401776)\t0.25392304109096725\n",
      "  (0, 394815)\t0.24640650445812856\n",
      "  (0, 390406)\t0.3972933108545502\n",
      "  (0, 374361)\t0.22348363749749403\n",
      "  (0, 337530)\t0.5234569549218435\n",
      "  (0, 231083)\t0.3307953247586049\n",
      "  (0, 134819)\t0.2732428887095021\n",
      "  (0, 80775)\t0.2653273474229123\n",
      "  (0, 68745)\t0.2640470757739768\n",
      "  (1, 385159)\t0.2423253397998145\n",
      "  (1, 366122)\t0.4811717662516511\n",
      "  (1, 270662)\t0.28298457606840066\n",
      "  (1, 229266)\t0.40540503595022426\n",
      "  (1, 153746)\t0.5748549434332728\n",
      "  (1, 17977)\t0.20793062743488835\n",
      "  (1, 8813)\t0.3026967059147128\n",
      "  (2, 460305)\t0.37056303922275935\n",
      "  (2, 457786)\t0.22643285141278216\n",
      "  (2, 439972)\t0.33256039758138023\n",
      "  (2, 428010)\t0.2705826510099419\n",
      "  (2, 395096)\t0.30217576065585394\n",
      "  (2, 272647)\t0.30725493909161034\n",
      "  (2, 132131)\t0.2729599284373498\n",
      "  (2, 114774)\t0.3685376425854966\n",
      "  :\t:\n",
      "  (319995, 323457)\t0.3883302771684808\n",
      "  (319995, 203834)\t0.3857804933967842\n",
      "  (319995, 187526)\t0.30322986158885457\n",
      "  (319995, 75382)\t0.32077047552960325\n",
      "  (319995, 24631)\t0.27967667213428454\n",
      "  (319995, 5659)\t0.30357657451224984\n",
      "  (319996, 460410)\t0.41405080650383386\n",
      "  (319996, 417655)\t0.9102537721061774\n",
      "  (319997, 466656)\t0.26696716041549107\n",
      "  (319997, 437812)\t0.29406608225347713\n",
      "  (319997, 368049)\t0.3247347567308167\n",
      "  (319997, 304123)\t0.48559758745432124\n",
      "  (319997, 275409)\t0.37226622901193746\n",
      "  (319997, 178542)\t0.40264334726028217\n",
      "  (319997, 105396)\t0.4475401490386847\n",
      "  (319998, 405372)\t0.3679553639665157\n",
      "  (319998, 171518)\t0.3752124946585065\n",
      "  (319998, 148160)\t0.2730090166657853\n",
      "  (319998, 135209)\t0.2922737211235663\n",
      "  (319998, 128649)\t0.35408305076673846\n",
      "  (319998, 57708)\t0.30575086355164\n",
      "  (319998, 48798)\t0.4892892252917659\n",
      "  (319998, 24631)\t0.32496805896995956\n",
      "  (319999, 420901)\t0.2873686612763943\n",
      "  (319999, 409533)\t0.957820052262539\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995965cd",
   "metadata": {},
   "source": [
    "Training the ML Model\n",
    "\n",
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63196639",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af34b5e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f82a24",
   "metadata": {},
   "source": [
    "Model Evaluation\n",
    "\n",
    "Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f35787a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy score on the trainning data\n",
    "\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "136f2c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training data: 0.8117670404430003\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score on the training data:', training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5924161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy score on the test data\n",
    "\n",
    "X_test_prediction = model.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(Y_test, X_test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c82df0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the test data: 0.7785375\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score on the test data:', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52187771",
   "metadata": {},
   "source": [
    "Model accuracy =77.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfc44e7",
   "metadata": {},
   "source": [
    "Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "961fdbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1e46cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'trained_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c758727",
   "metadata": {},
   "source": [
    "Using the saved model for future prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d095c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the saved model\n",
    "loaded_model = pickle.load(open('C:\\\\Users\\\\santh\\\\Untitled Folder\\\\trained_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0f9d34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1]\n",
      "Positive Tweet\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test[200]\n",
    "print(Y_test[200])\n",
    "\n",
    "prediction = model.predict(X_new)\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "if (prediction[0] == 0):\n",
    "  print('Negative Tweet')\n",
    "\n",
    "else:\n",
    "  print('Positive Tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "28c9b921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1]\n",
      "Positive Tweet\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test[3]\n",
    "print(Y_test[3])\n",
    "\n",
    "prediction = model.predict(X_new)\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "if (prediction[0] == 0):\n",
    "  print('Negative Tweet')\n",
    "\n",
    "else:\n",
    "  print('Positive Tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca54b44a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
